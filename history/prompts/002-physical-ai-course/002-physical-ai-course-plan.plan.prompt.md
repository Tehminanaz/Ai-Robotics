---
id: 002
title: Physical AI Course Plan Generated
stage: plan
date: 2025-11-30
surface: agent
model: claude-sonnet-4-5-20250929
feature: 002-physical-ai-course
branch: 002-physical-ai-course
user: null
command: /sp.plan
labels: ["planning", "architecture"]
links:
  spec: specs/002-physical-ai-course/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/002-physical-ai-course/plan.md
  - specs/002-physical-ai-course/research.md
  - specs/002-physical-ai-course/data-model.md
  - specs/002-physical-ai-course/quickstart.md
  - specs/002-physical-ai-course/contracts/
  - CLAUDE.md
tests:
  - null
---

## Prompt

```text
## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Outline

1. **Setup**: Run `.specify/scripts/powershell/setup-plan.ps1 -Json` from repo root and parse JSON for FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, BRANCH. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'''m Groot' (or double-quote if possible: "I'm Groot").

2. **Load context**: Read FEATURE_SPEC and `.specify/memory/constitution.md`. Load IMPL_PLAN template (already copied).

3. **Execute plan workflow**: Follow the structure in IMPL_PLAN template to:
   - Fill Technical Context (mark unknowns as "NEEDS CLARIFICATION")
   - Fill Constitution Check section from constitution
   - Evaluate gates (ERROR if violations unjustified)
   - Phase 0: Generate research.md (resolve all NEEDS CLARIFICATION)
   - Phase 1: Generate data-model.md, contracts/, quickstart.md
   - Phase 1: Update agent context by running the agent script
   - Re-evaluate Constitution Check post-design

4. **Stop and report**: Command ends after Phase 2 planning. Report branch, IMPL_PLAN path, and generated artifacts.

## Phases

### Phase 0: Outline & Research

1. **Extract unknowns from Technical Context** above:
   - For each NEEDS CLARIFICATION ‚Üí research task
   - For each dependency ‚Üí best practices task
   - For each integration ‚Üí patterns task

2. **Generate and dispatch research agents**:

   ```text
   For each unknown in Technical Context:
     Task: "Research {unknown} for {feature context}"
   For each technology choice:
     Task: "Find best practices for {tech} in {domain}"
   ```

3. **Consolidate findings** in `research.md` using format:
   - Decision: [what was chosen]
   - Rationale: [why chosen]
   - Alternatives considered: [what else evaluated]

**Output**: research.md with all NEEDS CLARIFICATION resolved

### Phase 1: Design & Contracts

**Prerequisites:** `research.md` complete

1. **Extract entities from feature spec** ‚Üí `data-model.md`:
   - Entity name, fields, relationships
   - Validation rules from requirements
   - State transitions if applicable

2. **Generate API contracts** from functional requirements:
   - For each user action ‚Üí endpoint
   - Use standard REST/GraphQL patterns
   - Output OpenAPI/GraphQL schema to `/contracts/`

3. **Agent context update**:
   - Run `.specify/scripts/powershell/update-agent-context.ps1 -AgentType claude`
   - These scripts detect which AI agent is in use
   - Update the appropriate agent-specific context file
   - Add only new technology from current plan
   - Preserve manual additions between markers

**Output**: data-model.md, /contracts/*, quickstart.md, agent-specific file

## Key rules

- Use absolute paths
- ERROR on gate failures or unresolved clarifications

---

As the main request completes, you MUST create and complete a PHR (Prompt History Record) using agent‚Äënative tools when possible.

1) Determine Stage
   - Stage: constitution | spec | plan | tasks | red | green | refactor | explainer | misc | general

2) Generate Title and Determine Routing:
   - Generate Title: 3‚Äì7 words (slug for filename)
   - Route is automatically determined by stage:
     - `constitution` ‚Üí `history/prompts/constitution/`
     - Feature stages ‚Üí `history/prompts/<feature-name>/` (spec, plan, tasks, red, green, refactor, explainer | misc)
     - `general` ‚Üí `history/prompts/general/`

3) Create and Fill PHR (Shell first; fallback agent‚Äënative)
   - Run: `.specify/scripts/bash/create-phr.sh --title "<title>" --stage <stage> [--feature <name>] --json`
   - Open the file and fill remaining placeholders (YAML + body), embedding full PROMPT_TEXT (verbatim) and concise RESPONSE_TEXT.
   - If the script fails:
     - Read `.specify/templates/phr-template.prompt.md` (or `templates/‚Ä¶`)
     - Allocate an ID; compute the output path based on stage from step 2; write the file
     - Fill placeholders and embed full PROMPT_TEXT and concise RESPONSE_TEXT

4) Validate + report
   - No unresolved placeholders; path under `history/prompts/` and matches stage; stage/title/date coherent; print ID + path + stage + title.
   - On failure: warn, don't block. Skip only for `/sp.phr`.
```

## Response snapshot

The `/sp.plan` command was executed to generate the implementation plan for the Physical AI Course Website feature. The plan.md file was updated, and research was conducted to fill in technical context details. Data model, quickstart guide, and contracts directory were created. The agent context in CLAUDE.md was also updated.

## Outcome

- ‚úÖ Impact: Plan for Physical AI Course Website generated successfully, including research, data model, and quickstart.
- üß™ Tests: No tests performed in this phase.
- üìÅ Files: Generated `plan.md`, `research.md`, `data-model.md`, `quickstart.md`, and `contracts/` directory. Updated `CLAUDE.md`.
- üîÅ Next prompts: Proceed to task generation (`/sp.tasks`).
- üß† Reflection: Successfully completed the planning phase as per the `/sp.plan` command instructions. Handled script execution failure by reverting to agent-native PHR creation.

## Evaluation notes (flywheel)

- Failure modes observed: Bash script execution failure for `create-phr.sh`.
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): Investigate direct bash script execution on Windows environment through `Bash` tool for `.sh` files.
